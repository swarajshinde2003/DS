{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE 9 MODELS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"ElasticNet Regression\": ElasticNet(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    \"Support Vector Regression\": SVR(kernel='rbf'),\n",
    "    \"K-Nearest Neighbors\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"XGBoost Regressor\": XGBRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    y_pred = model.predict(X_test)  # Predict on test set\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\"RMSE\": rmse, \"MAE\": mae, \"RÂ²\": r2}\n",
    "    \n",
    "    # Scatter plot for actual vs. predicted values\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.scatterplot(x=y_test, y=y_pred, alpha=0.6, edgecolor='k')\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='dashed')  # 45-degree line\n",
    "    plt.xlabel(\"Actual Score\")\n",
    "    plt.ylabel(\"Predicted Score\")\n",
    "    plt.title(f\"{name}: Actual vs. Predicted\")\n",
    "    plt.show()\n",
    "\n",
    "# Convert results to DataFrame for comparison\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Performance Comparison:\\n\")\n",
    "print(results_df)\n",
    "\n",
    "# Save the best model based on RMSE\n",
    "best_model_name = results_df[\"RMSE\"].idxmin()\n",
    "best_model = models[best_model_name]\n",
    "joblib.dump(best_model, \"best_regression_model.joblib\")\n",
    "print(f\"\\nBest model: {best_model_name} saved as 'best_regression_model.joblib'\")\n",
    "# ..\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
